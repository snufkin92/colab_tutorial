{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snufkin92/colab_tutorial/blob/master/section_12/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K74mqS_L8nq4"
      },
      "source": [
        "# 転移学習の実装\n",
        "巨大な画像データセット「ImageNet」により学習済みのモデルに、全結合層を追加します。  \n",
        "学習済みのモデルは訓練せずに、新たに追加した層のみを訓練して画像の分類を行います。  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3is6apnw8SIr"
      },
      "source": [
        "## 各設定\n",
        "tensorflowとKerasのバージョンによっては、Kerasのコードでエラーが発生することがあります。エラーを回避するために、以下のセルでKerasのバージョンを指定してインストールします。  \n",
        "以下のコードは、デフォルトのバージョンでエラーが発生しないときには必要ありません。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTv9ufF8ZrHS"
      },
      "source": [
        "!pip install keras==2.3  # 2020/3/28の時点ではtensorflow2.Xに対応するために必要"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvkSrhbY5EIF"
      },
      "source": [
        "なお、Googleの対応により上記のコードは近いうちに必要なくなるかと思います。  \n",
        "今後tensorflowやKerasのバージョンアップにより同様の問題が発生する可能性がありますが、上記のようにしてバージョンを調整することによる対応が必要になります。  \n",
        "上記のセルの実行後、**ランタイム→ランタイムを再起動**によりバージョンの更新が完了します。  \n",
        "念のために、以下のコードによりバージョンを確認しておきましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3StnqCjarNc"
      },
      "source": [
        "import tensorflow\n",
        "import keras\n",
        "print(tensorflow.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttmC5S-EaYLA"
      },
      "source": [
        "必要なモジュールのインポート、最適化アルゴリズムの設定、及び各定数の設定を行います。  \n",
        "今回はCIFAR-10の分類を行うので、画像の幅と高さは32、チャンネル数は3に設定します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6Ts3siI8awo"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "optimizer = Adam()\n",
        "\n",
        "img_size = 64  # 画像の幅と高さ\n",
        "n_channel = 3  # チャンネル数\n",
        "n_mid = 256  # 中間層のニューロン数\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSlMwCaB9qpb"
      },
      "source": [
        "## VGG16の導入\n",
        "ImageNetを使って訓練済みのモデル、VGG16をkeras.applicationsから導入します。  \n",
        "今回はこのモデルを特徴の抽出のために使用しますが、追加の訓練は行いません。  \n",
        "https://keras.io/ja/applications/#vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAwr34WSbTzc"
      },
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "model_vgg16 = VGG16(weights=\"imagenet\",  # ImageNetで学習したパラメータを使用\n",
        "                 include_top=False,  # 全結合層を含まない\n",
        "                 input_shape=(img_size, img_size, n_channel))  # 入力の形状\n",
        "model_vgg16.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r4JK36TB9Kp"
      },
      "source": [
        "## CIFAR-10\n",
        "Kerasを使い、CIFAR-10を読み込みます。  \n",
        "今回はこのうち飛行機と自動車の画像のみ使い、画像が飛行機か自動車かを判定できるように新たに追加した層を訓練します。  \n",
        "以下のコードでは、CIFAR-10を読み込み、ランダムな25枚の画像を表示します。  \n",
        "元の画像サイズは32×32なのですが、VGG16の入力は48x48以上のサイズである必要があるため、NumPyのrepeat関数によりサイズを2倍に調整します。  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzdxGrl_maKl"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = cifar10.load_data()\n",
        "\n",
        "# ラベルが0と1のデータのみ取り出す\n",
        "t_train = t_train.reshape(-1)\n",
        "t_test = t_test.reshape(-1)\n",
        "x_train = x_train[t_train <= 1]\n",
        "t_train = t_train[t_train <= 1]\n",
        "x_test = x_test[t_test <= 1]\n",
        "t_test = t_test[t_test <= 1]\n",
        "\n",
        "print(\"Original size:\", x_train.shape)\n",
        "\n",
        "# 画像を拡大\n",
        "x_train = x_train.repeat(2, axis=1).repeat(2, axis=2)\n",
        "x_test = x_test.repeat(2, axis=1).repeat(2, axis=2)\n",
        "\n",
        "print(\"Input size:\", x_train.shape)\n",
        "\n",
        "n_image = 25\n",
        "rand_idx = np.random.randint(0, len(x_train), n_image)\n",
        "cifar10_labels = np.array([\"airplane\", \"automobile\"])\n",
        "plt.figure(figsize=(10,10))  # 画像の表示サイズ\n",
        "for i in range(n_image):\n",
        "    cifar_img=plt.subplot(5,5,i+1)\n",
        "    plt.imshow(x_train[rand_idx[i]])\n",
        "    label = cifar10_labels[t_train[rand_idx[i]]]\n",
        "    plt.title(label)\n",
        "    plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False)  # ラベルと目盛りを非表示に"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZINZ7oPyabc"
      },
      "source": [
        "## モデルの構築\n",
        "導入したVGG16に全結合層を追加します。  \n",
        "訓練するのは追加した全結合層のみで、VGG16の層は訓練しません。  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc3u8T6sbD7D"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(model_vgg16)\n",
        "\n",
        "model.add(Flatten())  # 一次元の配列に変換\n",
        "model.add(Dense(n_mid))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))  # ドロップアウト\n",
        "model.add(Dense(1))\n",
        "model.add(Activation(\"sigmoid\"))\n",
        "\n",
        "model_vgg16.trainable = False  # 訓練済みの層は訓練しない\n",
        "\n",
        "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtalwFaJUDd4"
      },
      "source": [
        "## 学習\n",
        "モデルを訓練します。  \n",
        "過学習を防ぐために、データ拡張を導入します。  \n",
        "学習には時間がかかりますので、編集→ノートブックの設定のハードウェアアクセラレーターでGPUを選択しましょう。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0tjdUZfUPQ6"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "x_train = x_train / 255  # 0から1の範囲に収める\n",
        "x_test = x_test / 255\n",
        "\n",
        "# データ拡張\n",
        "generator = ImageDataGenerator(\n",
        "           rotation_range=0.2,\n",
        "           width_shift_range=0.2,\n",
        "           height_shift_range=0.2,\n",
        "           shear_range=10,\n",
        "           zoom_range=0.2,\n",
        "           horizontal_flip=True)\n",
        "generator.fit(x_train)\n",
        "\n",
        "# 訓練\n",
        "history = model.fit_generator(generator.flow(x_train, t_train, batch_size=batch_size),\n",
        "                              epochs=epochs,\n",
        "                              validation_data=(x_test, t_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jfcSh93hxWt"
      },
      "source": [
        "## 学習の推移\n",
        "historyを使って、学習の推移を確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv-Rxwn5jhQM"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_loss = history.history['loss']  # 訓練用データの誤差\n",
        "train_acc = history.history['accuracy']  # 訓練用データの精度\n",
        "val_loss = history.history['val_loss']  # 検証用データの誤差\n",
        "val_acc = history.history['val_accuracy']  # 検証用データの精度\n",
        "\n",
        "plt.plot(np.arange(len(train_loss)), train_loss, label='loss')\n",
        "plt.plot(np.arange(len(val_loss)), val_loss, label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(np.arange(len(train_acc)), train_acc, label='acc')\n",
        "plt.plot(np.arange(len(val_acc)), val_acc, label='val_acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6ohk2o3Ajtb"
      },
      "source": [
        "訓練済みのモデルを特徴の抽出に用いることで、追加した全結合層を訓練するのみでも画像の分類が可能であることが確認できました。"
      ]
    }
  ]
}