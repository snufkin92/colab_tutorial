{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snufkin92/colab_tutorial/blob/master/section_08/distributed_expression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYT1yKCN9vtr"
      },
      "source": [
        "# 分散表現の確認\n",
        "word2vecによる分散表現について学びます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT3h7mKs9vtt"
      },
      "source": [
        "## コーパスの前処理\n",
        "前のセクションと同様に、コーパスに前処理を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GH_rXBZZ9vtt"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pickle\n",
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "with open(\"wagahaiwa_nekodearu.txt\", mode=\"r\", encoding=\"utf-8\") as f:  # ファイルの読み込み\n",
        "    wagahai_original = f.read()\n",
        "\n",
        "wagahai = re.sub(\"《[^》]+》\", \"\", wagahai_original) # ルビの削除\n",
        "wagahai = re.sub(\"［[^］]+］\", \"\", wagahai) # 読みの注意の削除\n",
        "wagahai = re.sub(\"[｜ 　「」\\n]\", \"\", wagahai) # | と全角半角スペース、「」と改行の削除\n",
        "\n",
        "seperator = \"。\"  # 。をセパレータに指定\n",
        "wagahai_list = wagahai.split(seperator)  # セパレーターを使って文章をリストに分割する\n",
        "wagahai_list.pop() # 最後の要素は空の文字列になるので、削除\n",
        "wagahai_list = [x+seperator for x in wagahai_list]  # 文章の最後に。を追加\n",
        "\n",
        "t = Tokenizer()\n",
        "\n",
        "wagahai_words = []\n",
        "for sentence in wagahai_list:\n",
        "    wagahai_words.append(list(t.tokenize(sentence, wakati=True)))  # 文章ごとに単語に分割し、リストに格納\n",
        "\n",
        "with open('wagahai_words.pickle', mode='wb') as f:  # pickleに保存\n",
        "    pickle.dump(wagahai_words, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlrsmUAw9vtt"
      },
      "source": [
        "保存できていることを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMzNIrLb9vtv",
        "outputId": "dcde7fb0-5def-48f1-964c-79f83e5efef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['吾輩', 'は', '猫', 'で', 'ある', '。'], ['名前', 'は', 'まだ', '無い', '。'], ['どこ', 'で', '生れ', 'た', 'か', 'とんと', '見当', 'が', 'つか', 'ぬ', '。'], ['何', 'でも', '薄暗い', 'じめじめ', 'し', 'た', '所', 'で', 'ニャーニャー', '泣い', 'て', 'いた事', 'だけ', 'は', '記憶', 'し', 'て', 'いる', '。'], ['吾輩', 'は', 'ここ', 'で', '始め', 'て', '人間', 'という', 'もの', 'を', '見', 'た', '。'], ['しかも', 'あと', 'で', '聞く', 'と', 'それ', 'は', '書生', 'という', '人間', '中', 'で', '一番', '獰悪', 'な', '種族', 'で', 'あっ', 'た', 'そう', 'だ', '。'], ['この', '書生', 'という', 'の', 'は', '時々', '我々', 'を', '捕え', 'て', '煮', 'て', '食う', 'という', '話', 'で', 'ある', '。'], ['しかし', 'その', '当時', 'は', '何', 'という', '考', 'も', 'なかっ', 'た', 'から', '別段', '恐し', 'いとも', '思わ', 'なかっ', 'た', '。'], ['ただ', '彼', 'の', '掌', 'に', '載せ', 'られ', 'て', 'スー', 'と', '持ち上げ', 'られ', 'た', '時', '何だか', 'フワフワ', 'し', 'た', '感じ', 'が', 'あっ', 'た', 'ばかり', 'で', 'ある', '。'], ['掌', 'の', '上', 'で', '少し', '落ちつい', 'て', '書生', 'の', '顔', 'を', '見', 'た', 'の', 'が', 'いわゆる', '人間', 'という', 'もの', 'の', '見', '始', 'で', 'あろ', 'う', '。']]\n"
          ]
        }
      ],
      "source": [
        "with open('wagahai_words.pickle', mode='rb') as f:\n",
        "    wagahai_words = pickle.load(f)\n",
        "\n",
        "print(wagahai_words[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgQ00nkH9vtv"
      },
      "source": [
        "## word2vecを用いた学習\n",
        "今回はword2vecのためにライブラリgensimを使います。  \n",
        "gensimは、様々なトピックモデルを実装したPythonライブラリです。  \n",
        "トピックモデルとは、潜在的なトピックから文章が確率的に生成されると仮定したモデルです。\n",
        "\n",
        "gensimについて、詳細は以下のリンクを参考にどうぞ。  \n",
        "https://radimrehurek.com/gensim/\n",
        "\n",
        "以下では、word2vecを用いてコーパスの学習を行い、学習済みのモデルを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16Fevvi19vtv",
        "outputId": "59efafec-9149-4787-c480-a196d7bed84e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[['吾輩', 'は', '猫', 'で', 'ある', '。'],\n",
              " ['名前', 'は', 'まだ', '無い', '。'],\n",
              " ['どこ', 'で', '生れ', 'た', 'か', 'とんと', '見当', 'が', 'つか', 'ぬ', '。']]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(type(wagahai_words))\n",
        "wagahai_words[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhiC2sxL9vtv"
      },
      "outputs": [],
      "source": [
        "# scipy=1.12.0を使わないとImportError: cannot import name 'triu' from 'scipy.linalg' が発生\n",
        "from gensim.models import word2vec\n",
        "\n",
        "# vector_size : 中間層のニューロン数\n",
        "# min_count : この値以下の出現回数の単語を無視\n",
        "# window : 対象単語を中心とした前後の単語数\n",
        "# epochs : epochs数\n",
        "# sg : skip-gramを使うかどうか 0:CBOW 1:skip-gram\n",
        "model = word2vec.Word2Vec(wagahai_words,\n",
        "                          vector_size=100,\n",
        "                          min_count=5,\n",
        "                          window=5,\n",
        "                          epochs=20,\n",
        "                          sg = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZKl_gex9vtw"
      },
      "source": [
        "分散表現を見ていきましょう。  \n",
        "重みを表す行列（分散表現）の形状と、行列そのものを表示します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgHk0hf39vtx",
        "outputId": "181343df-aeee-47d5-faa8-99a8aeb1f02a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3309, 100)\n",
            "[[-0.13262224  0.6376691   0.9703918  ... -0.83940995  0.6842959\n",
            "   0.5759229 ]\n",
            " [-0.8580033  -0.66843766  1.4828197  ... -0.47005606 -0.33892664\n",
            "  -0.17183577]\n",
            " [ 0.47351834  0.24001913 -1.0540961  ... -0.4554502   0.34211117\n",
            "  -0.03961928]\n",
            " ...\n",
            " [ 0.03896393  0.06777891  0.03392925 ... -0.12314384 -0.0132106\n",
            "  -0.06999081]\n",
            " [-0.16052945  0.11881156  0.15593597 ... -0.11861178  0.13037367\n",
            "  -0.06686825]\n",
            " [-0.08516419 -0.06244256 -0.00626748 ... -0.1691904   0.04974204\n",
            "  -0.0372024 ]]\n"
          ]
        }
      ],
      "source": [
        "print(model.wv.vectors.shape)  # 分散表現の形状\n",
        "print(model.wv.vectors)  # 分散表現"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvDP9el99vty"
      },
      "source": [
        "3309個の単語が100次元で表現されている"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqfxrbMH9vty"
      },
      "source": [
        "語彙の数、および語彙の最初の10語を表示します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppwTkijp9vty",
        "outputId": "2a2b9a60-5c38-4295-83a9-108dcaa95cc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3309\n",
            "['の', '。', 'て', '、', 'は', 'に', 'を', 'と', 'が', 'た']\n"
          ]
        }
      ],
      "source": [
        "print(len(model.wv.index_to_key))  # 語彙の数\n",
        "print(model.wv.index_to_key[:10])  # 最初の10単語"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbbnewlE9vtz"
      },
      "source": [
        "語彙における、最初の単語の単語ベクトルを2通りの方法で表示します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNOuBwmL9vtz",
        "outputId": "45e00e6e-a08c-4c0e-9d4e-97ab69542579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-1.32622242e-01  6.37669086e-01  9.70391810e-01  6.19177222e-01\n",
            " -8.04323852e-01  1.02501303e-01  5.10776937e-01  4.11223263e-01\n",
            " -5.13011396e-01 -1.30582391e-03  2.30451003e-01  1.74877167e-01\n",
            " -6.38507962e-01  4.77089971e-01 -5.17559469e-01  1.82515487e-01\n",
            " -4.56721663e-01 -6.80352569e-01 -2.65191525e-01  4.51699823e-01\n",
            "  7.00099647e-01 -9.87528637e-02  3.00687373e-01  1.08244693e+00\n",
            " -3.18306476e-01  2.11888433e-01 -4.26928043e-01  9.27322954e-02\n",
            "  1.02046825e-01 -5.75903237e-01 -1.27754486e+00  7.90337250e-02\n",
            "  3.15923765e-02 -3.62777978e-01  6.08772457e-01  6.56754255e-01\n",
            " -1.62177220e-01 -7.44768500e-01 -1.63632959e-01 -7.74770200e-01\n",
            " -9.56861615e-01 -3.66354227e-01 -1.25183713e+00  5.17315924e-01\n",
            "  5.71118116e-01  5.95237970e-01 -5.19761503e-01 -2.89529622e-01\n",
            "  2.58446991e-01  7.28476703e-01 -1.95298623e-02  7.87290215e-01\n",
            " -7.55575657e-01  7.69167244e-01 -5.73947489e-01 -4.16455328e-01\n",
            " -3.53526503e-01 -8.58177423e-01 -8.32668304e-01  2.38506012e-02\n",
            " -8.91649246e-01 -2.39230752e-01  3.87327611e-01 -6.08912468e-01\n",
            "  4.05483186e-01 -9.00921583e-01  1.46633228e-02  1.03505242e+00\n",
            " -2.54015803e-01  4.90857102e-02 -2.56596282e-02  7.00274348e-01\n",
            " -6.22826993e-01 -6.07488394e-01  5.79102397e-01 -2.32837811e-01\n",
            "  1.23855807e-01  3.48574162e-01  2.99439818e-01  2.19512939e-01\n",
            " -9.39307734e-02 -5.85009530e-02  1.60462058e+00 -5.56511223e-01\n",
            " -7.64707386e-01 -2.36779705e-01 -1.02505460e-01 -1.79555938e-01\n",
            " -2.34838516e-01 -1.16568044e-01 -7.59948641e-02  2.11484969e-01\n",
            "  4.13334221e-02  2.06252187e-01  8.53427708e-01  5.20960450e-01\n",
            "  2.86458373e-01 -8.39409947e-01  6.84295893e-01  5.75922906e-01]\n"
          ]
        }
      ],
      "source": [
        "print(model.wv.vectors[0])  # 最初のベクトル"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSY2XJUo9vtz",
        "outputId": "da07bdfa-94bb-4340-9623-c5702552028b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-1.32622242e-01  6.37669086e-01  9.70391810e-01  6.19177222e-01\n",
            " -8.04323852e-01  1.02501303e-01  5.10776937e-01  4.11223263e-01\n",
            " -5.13011396e-01 -1.30582391e-03  2.30451003e-01  1.74877167e-01\n",
            " -6.38507962e-01  4.77089971e-01 -5.17559469e-01  1.82515487e-01\n",
            " -4.56721663e-01 -6.80352569e-01 -2.65191525e-01  4.51699823e-01\n",
            "  7.00099647e-01 -9.87528637e-02  3.00687373e-01  1.08244693e+00\n",
            " -3.18306476e-01  2.11888433e-01 -4.26928043e-01  9.27322954e-02\n",
            "  1.02046825e-01 -5.75903237e-01 -1.27754486e+00  7.90337250e-02\n",
            "  3.15923765e-02 -3.62777978e-01  6.08772457e-01  6.56754255e-01\n",
            " -1.62177220e-01 -7.44768500e-01 -1.63632959e-01 -7.74770200e-01\n",
            " -9.56861615e-01 -3.66354227e-01 -1.25183713e+00  5.17315924e-01\n",
            "  5.71118116e-01  5.95237970e-01 -5.19761503e-01 -2.89529622e-01\n",
            "  2.58446991e-01  7.28476703e-01 -1.95298623e-02  7.87290215e-01\n",
            " -7.55575657e-01  7.69167244e-01 -5.73947489e-01 -4.16455328e-01\n",
            " -3.53526503e-01 -8.58177423e-01 -8.32668304e-01  2.38506012e-02\n",
            " -8.91649246e-01 -2.39230752e-01  3.87327611e-01 -6.08912468e-01\n",
            "  4.05483186e-01 -9.00921583e-01  1.46633228e-02  1.03505242e+00\n",
            " -2.54015803e-01  4.90857102e-02 -2.56596282e-02  7.00274348e-01\n",
            " -6.22826993e-01 -6.07488394e-01  5.79102397e-01 -2.32837811e-01\n",
            "  1.23855807e-01  3.48574162e-01  2.99439818e-01  2.19512939e-01\n",
            " -9.39307734e-02 -5.85009530e-02  1.60462058e+00 -5.56511223e-01\n",
            " -7.64707386e-01 -2.36779705e-01 -1.02505460e-01 -1.79555938e-01\n",
            " -2.34838516e-01 -1.16568044e-01 -7.59948641e-02  2.11484969e-01\n",
            "  4.13334221e-02  2.06252187e-01  8.53427708e-01  5.20960450e-01\n",
            "  2.86458373e-01 -8.39409947e-01  6.84295893e-01  5.75922906e-01]\n"
          ]
        }
      ],
      "source": [
        "print(model.wv.__getitem__(\"の\"))  # 最初の単語「の」のベクトル"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "virgcwH39vtz"
      },
      "source": [
        "両者ともに同じベクトルですね。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X4kcxaN9vtz"
      },
      "source": [
        "## 課題:\n",
        "単語「猫」を単語ベクトルで表してみましょう。  \n",
        "また、skip-gramも試して結果を比較してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8LzZVoN9vt0",
        "outputId": "a4bc92b9-eb20-4c89-eb01-3da2ece54aaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.49389535 -0.5368431   0.01848227 -0.2998496   0.14273547  0.8160949\n",
            " -0.7390623   0.9594122   1.2501879  -0.04962321  0.76159286  1.0826745\n",
            " -0.22315796  0.08589792 -0.31518108  0.09116571  0.18727177 -0.3275528\n",
            "  0.6151032  -0.02364909  0.7297533   0.11873629  1.0472162  -0.24857353\n",
            "  0.32181436  0.6682793  -1.004732   -0.5469218   0.71741164  0.77665603\n",
            " -1.8105392  -0.20079927 -0.05320627 -1.0941718   0.37810582  0.45051005\n",
            "  0.41972822 -0.54603505 -0.08725882 -0.22658247 -1.0787129  -0.32814866\n",
            "  0.34240833  0.3828128  -0.19413543 -0.04672657  0.7432857  -1.2522031\n",
            " -0.09242587 -0.25035205 -1.7908078   0.6343977  -0.3772061   0.1019305\n",
            "  1.3225694  -0.58262074 -0.06361256 -0.7413524   0.9291293   1.8064713\n",
            "  0.4359546  -0.29224864 -0.09469255 -0.3409965  -1.2350273  -0.26646197\n",
            " -0.04862994  1.5623655  -0.56125766  0.66185653  0.7274623  -0.22990547\n",
            "  0.784491   -0.15230495  0.21330275 -0.87824094  0.0054565   0.46843407\n",
            " -0.64842165 -0.5134241  -0.6845294   0.62715876 -0.5207381   1.213873\n",
            " -0.5735813  -0.09912062  0.33646795  0.4234577  -0.28576186 -0.3948561\n",
            "  0.59887356 -0.11074468  0.9249348  -0.22024982  0.75666356  0.7691106\n",
            "  0.09341126  0.45021826 -0.11482237 -0.46593088]\n"
          ]
        }
      ],
      "source": [
        "print(model.wv.__getitem__(\"猫\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRb3AStX9vt0"
      },
      "outputs": [],
      "source": [
        "from gensim.models import word2vec\n",
        "\n",
        "model_skip = word2vec.Word2Vec(wagahai_words,\n",
        "                          vector_size=100,\n",
        "                          min_count=5,\n",
        "                          window=5,\n",
        "                          epochs=20,\n",
        "                          sg = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YT0bKag9vt0",
        "outputId": "d86bb122-805a-4d7b-ba0b-5c4a379aec38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3309, 100)\n",
            "[-0.08673591  0.30820256 -0.02953538  0.13294083 -0.36908588  0.7193044\n",
            "  0.06363755  0.66458195  0.71625227  0.24718437  1.0639889   0.28868714\n",
            "  0.05032108  0.32984638 -0.1912864   0.06336804  0.22127911 -0.2506569\n",
            "  0.2996364  -0.2892944   0.3804191   0.22440371 -0.3426052   0.84506214\n",
            "  0.01301781  0.06392673 -0.96968764 -0.30992478  0.11135981  0.42982787\n",
            " -0.45565283 -0.14300655 -0.6164357  -0.6803418  -0.12909864  0.49735367\n",
            "  0.36628085 -0.04091739 -0.3316552  -0.2056428   0.26770827  0.5224419\n",
            "  0.12160255 -0.0652353  -0.28884235  0.5131209   0.45722276 -0.5391972\n",
            "  0.58661693  0.15865748 -0.22856441 -0.20202272 -0.5046227  -0.31021357\n",
            " -0.4292442   0.13184759  0.10953931 -0.02671878 -0.0860863   0.5744976\n",
            "  0.14074619 -0.2067359  -0.40397412 -0.0808498  -0.5287643   0.415613\n",
            " -0.14085338  1.2002153  -0.49014428  0.2723026  -0.0326972   0.43525562\n",
            "  0.02252262  0.42087543 -0.04105791  0.08798922  0.15534075  0.22250989\n",
            " -0.46786666 -0.26777902  0.3262293  -0.08035211 -0.67894775  0.8012646\n",
            "  0.47129968 -0.15128551 -0.52075255 -0.37478572  0.11045105  0.23477544\n",
            "  0.11872889  0.59997654  0.17986535  0.25888938  0.67014873  0.08878449\n",
            " -0.02335123  0.47455844  0.28381667 -0.09612313]\n"
          ]
        }
      ],
      "source": [
        "print(model_skip.wv.vectors.shape)  # 分散表現の形状\n",
        "\n",
        "# 猫の分散表現（CBOWと違う！）\n",
        "print(model_skip.wv.__getitem__(\"猫\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zznqCAwD9vt0"
      },
      "source": [
        "猫の分散表現がCBOWと違う！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoCee78Y9vt0",
        "outputId": "8cd5206b-0731-49bc-f0be-980789efb0a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.22383127  0.2792024  -0.47555608  0.52744585 -0.11830074  0.22855282\n",
            "  0.72555864  0.32415372  0.16922261 -0.2024026  -0.4543991  -0.18941857\n",
            "  0.32629433  0.1830218  -0.16302624  0.01073745  0.0799717  -0.11806955\n",
            "  0.14646496 -0.36892864 -0.1309027   0.2595161   0.03119702  0.40649137\n",
            " -0.36538404 -0.08947231 -0.08917995  0.28545022  0.23824848  0.35414687\n",
            " -0.360418    0.2725609   0.09482723 -0.18300706 -0.03456452  0.28644374\n",
            " -0.1051873  -0.19834138  0.04621578 -0.37643468  0.22198312  0.02431218\n",
            " -0.3601935  -0.36572218  0.31109503  0.68825245 -0.20120008 -0.30870935\n",
            "  0.31606176 -0.18483147  0.0857709  -0.06918326 -0.7218825   0.02768981\n",
            "  0.08873706  0.10635679 -0.17264205 -0.59647065 -0.14882423 -0.20247896\n",
            " -0.14408056 -0.01363565  0.15590867 -0.337324   -0.05907686  0.32930323\n",
            " -0.16766925  0.8017681  -0.17871675  0.28338227  0.0134429  -0.15083429\n",
            "  0.18113148 -0.38019818  0.10878071  0.08877594  0.13210435  0.17675166\n",
            " -0.14678341 -0.28720695  0.41396576 -0.09059002 -0.2759024   0.30450794\n",
            "  0.18945147 -0.23652527  0.01259391  0.1616081   0.21196543  0.18021102\n",
            " -0.18554212  0.24516818  0.77684647  0.3004901   0.73027444 -0.12421712\n",
            " -0.09122368 -0.22279766  0.65521127  0.54186404]\n"
          ]
        }
      ],
      "source": [
        "print(model_skip.wv.__getitem__(\"黒\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IeCgCHw9vt1",
        "outputId": "ef86e070-9e4c-41b1-a913-c39bcd6eb4bf"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"Key '黒猫' not present\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel_skip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m黒猫\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m) \n",
            "File \u001b[0;32m~/workspace/vscode/99_nlp/.nlp_venv/lib/python3.9/site-packages/gensim/models/keyedvectors.py:403\u001b[0m, in \u001b[0;36mKeyedVectors.__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get vector representation of `key_or_keys`.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_or_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m key_or_keys])\n",
            "File \u001b[0;32m~/workspace/vscode/99_nlp/.nlp_venv/lib/python3.9/site-packages/gensim/models/keyedvectors.py:446\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vector\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    423\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \n\u001b[1;32m    425\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m \n\u001b[1;32m    445\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm:\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_norms()\n",
            "File \u001b[0;32m~/workspace/vscode/99_nlp/.nlp_venv/lib/python3.9/site-packages/gensim/models/keyedvectors.py:420\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Key '黒猫' not present\""
          ]
        }
      ],
      "source": [
        "# 黒猫という単語は学習していないからエラー\n",
        "print(model_skip.wv.__getitem__(\"黒猫\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9qNyfUP9vt1"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}