{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snufkin92/colab_tutorial/blob/master/section_08/word_similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YvzVoPg5qoW"
      },
      "source": [
        "# 単語の類似度\n",
        "word2vecを用いて、2つの単語の類似度を求めます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v97WDIpe5qoX"
      },
      "source": [
        "## データの読み込み、及びword2vecによる学習\n",
        "前回と同様に、データの読み込み及びword2vecによる学習を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvO69twx5qoX",
        "outputId": "73099c6d-22a3-44a9-dc11-2d04595c9f59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['吾輩', 'は', '猫', 'で', 'ある', '。'], ['名前', 'は', 'まだ', '無い', '。'], ['どこ', 'で', '生れ', 'た', 'か', 'とんと', '見当', 'が', 'つか', 'ぬ', '。'], ['何', 'でも', '薄暗い', 'じめじめ', 'し', 'た', '所', 'で', 'ニャーニャー', '泣い', 'て', 'いた事', 'だけ', 'は', '記憶', 'し', 'て', 'いる', '。'], ['吾輩', 'は', 'ここ', 'で', '始め', 'て', '人間', 'という', 'もの', 'を', '見', 'た', '。'], ['しかも', 'あと', 'で', '聞く', 'と', 'それ', 'は', '書生', 'という', '人間', '中', 'で', '一番', '獰悪', 'な', '種族', 'で', 'あっ', 'た', 'そう', 'だ', '。'], ['この', '書生', 'という', 'の', 'は', '時々', '我々', 'を', '捕え', 'て', '煮', 'て', '食う', 'という', '話', 'で', 'ある', '。'], ['しかし', 'その', '当時', 'は', '何', 'という', '考', 'も', 'なかっ', 'た', 'から', '別段', '恐し', 'いとも', '思わ', 'なかっ', 'た', '。'], ['ただ', '彼', 'の', '掌', 'に', '載せ', 'られ', 'て', 'スー', 'と', '持ち上げ', 'られ', 'た', '時', '何だか', 'フワフワ', 'し', 'た', '感じ', 'が', 'あっ', 'た', 'ばかり', 'で', 'ある', '。'], ['掌', 'の', '上', 'で', '少し', '落ちつい', 'て', '書生', 'の', '顔', 'を', '見', 'た', 'の', 'が', 'いわゆる', '人間', 'という', 'もの', 'の', '見', '始', 'で', 'あろ', 'う', '。']]\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from gensim.models import word2vec\n",
        "\n",
        "with open('wagahai_words.pickle', mode='rb') as f:\n",
        "    wagahai_words = pickle.load(f)\n",
        "\n",
        "print(wagahai_words[:10])\n",
        "\n",
        "# vector_size : 中間層のニューロン数\n",
        "# min_count : この値以下の出現回数の単語を無視\n",
        "# window : 対象単語を中心とした前後の単語数\n",
        "# epochs : epochs数\n",
        "# sg : CBOWを使うかskip-gramを使うか 0:CBOW 1:skip-gram\n",
        "model = word2vec.Word2Vec(wagahai_words,\n",
        "                          vector_size=100,\n",
        "                          min_count=5,\n",
        "                          window=5,\n",
        "                          epochs=20,\n",
        "                          sg = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWg7THfq5qoX"
      },
      "source": [
        "## 類似度の高い単語\n",
        "ある単語と類似度の高い単語を表示します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u9Wr0RY5qoX",
        "outputId": "8611ef7d-37b5-48c0-ab1c-9e60aca4086b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('人間', 0.7420498132705688), ('教師', 0.660339891910553), ('罪', 0.6461361050605774), ('事実', 0.638360857963562), ('君子', 0.6317129135131836), ('充分', 0.6296736001968384), ('性質', 0.6108419299125671), ('世の中', 0.606779158115387), ('者', 0.6065337657928467), ('普通', 0.595708429813385)]\n"
          ]
        }
      ],
      "source": [
        "print(model.wv.most_similar(\"猫\"))  # 最も似ている単語"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fan6kOS5qoY",
        "outputId": "90718e6d-3f62-4b49-b0fc-42d36f864d66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('属', 0.5449262261390686), ('教師', 0.5040985345840454), ('人間', 0.499581903219223), ('一疋', 0.4977529048919678), ('有様', 0.47267118096351624), ('せめて', 0.4707314670085907), ('動作', 0.4685066044330597), ('遥か', 0.45443010330200195), ('上等', 0.45317742228507996), ('進化', 0.4474957585334778)]\n"
          ]
        }
      ],
      "source": [
        "model_skip = word2vec.Word2Vec(wagahai_words,\n",
        "                          vector_size=100,\n",
        "                          min_count=5,\n",
        "                          window=5,\n",
        "                          epochs=20,\n",
        "                          sg = 1)\n",
        "\n",
        "print(model_skip.wv.most_similar(\"猫\"))  # 最も似ている単語"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EsT_v9S5qoY"
      },
      "source": [
        "学習データが小さいため、今回はあまり興味深い結果にはなりません。  \n",
        "興味のある方は、他の小説をなどをコーパスに加え、学習データを大きくしてみましょう。  \n",
        "\n",
        "なお、単語の類似度は以下の式で表されるコサイン類似度で計算しています。  \n",
        "ベクトル$\\vec{a}=(a_1,a_2,\\cdots, a_n)$、$\\vec{b}=(b_1,b_2,\\cdots, b_n)$として、\n",
        "$$\\frac{a_1b_1+a_2b_2+\\cdots + a_nb_n}{\\sqrt{a_1^2+a_2^2+\\cdots+a_n^2}\\sqrt{b_1^2+b_2^2+\\cdots+b_n^2}}$$\n",
        "\n",
        "試しに、コサイン類似度を計算してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uV93Mjq5qoY",
        "outputId": "3f0a053b-27e7-4e28-abba-c2318b928f50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.74204975\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "a = model.wv.__getitem__(\"猫\")\n",
        "b = model.wv.__getitem__(\"人間\")\n",
        "cos_sim = np.dot(a, b) / np.linalg.norm(a) / np.linalg.norm(b)  # linalg.normで二乗和の平方根（ノルム）を計算\n",
        "print(cos_sim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0vu_ukW5qoY"
      },
      "source": [
        "猫と人間の類似度は、先ほどの結果と同じになりました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okIOMGr25qoY"
      },
      "source": [
        "## 課題:\n",
        "「名前」という単語と類似度の高い単語を表示してみましょう。  \n",
        "また、最も類似度が高い単語とのコサイン類似度を計算してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZE7gmo425qoZ",
        "outputId": "0ae55162-6cce-4e55-8da5-ad6aa985b65f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('娘', 0.7289959192276001), ('変り', 0.6892088055610657), ('どっち', 0.6885676980018616), ('冗談', 0.6807710528373718), ('ありゃ', 0.6774534583091736), ('泥棒', 0.6749650835990906), ('名', 0.661446750164032), ('約束', 0.6610537171363831), ('結婚', 0.660773754119873), ('罪', 0.6579711437225342)]\n"
          ]
        }
      ],
      "source": [
        "print(model.wv.most_similar(\"名前\"))  # 最も似ている単語"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmrVJycr5qoa",
        "outputId": "3733c975-ba09-4fd3-a364-e84361d4626e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.72899586\n"
          ]
        }
      ],
      "source": [
        "c = model.wv.__getitem__(\"名前\")\n",
        "d = model.wv.__getitem__(\"娘\")\n",
        "\n",
        "cos_sim = np.dot(c, d) / np.linalg.norm(c) / np.linalg.norm(d)  # linalg.normで二乗和の平方根（ノルム）を計算\n",
        "print(cos_sim)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}